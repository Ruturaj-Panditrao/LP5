{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_75MtwpQ5UW",
        "outputId": "f700c6e7-d3f7-4bcc-bb48-b3acd67d2ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Ruturaj-Panditrao/cuda.git\n",
            "  Cloning https://github.com/Ruturaj-Panditrao/cuda.git to /tmp/pip-req-build-q9fllycq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Ruturaj-Panditrao/cuda.git /tmp/pip-req-build-q9fllycq\n",
            "  Resolved https://github.com/Ruturaj-Panditrao/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "# Steps to Run Cuda on Google Colab/ Jupyter Notebook\n",
        "# Change runtime to GPU and run this cell\n",
        "\n",
        "!pip install git+https://github.com/Ruturaj-Panditrao/cuda.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Steps to Run Cuda on Linux Command Line (here let us assume file name is abc)\n",
        "# nvcc --version\n",
        "# cat>> abc.cu\n",
        "# Paste the code, then press Ctrl+D\n",
        "# nvcc abc.cu\n",
        "# ./a.out"
      ],
      "metadata": {
        "id": "DMUtuc8XlTyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "#include<bits/stdc++.h>\n",
        "#include<cuda.h>\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "\n",
        "void initialize_matrix(int *array, int rows, int cols){\n",
        "    for(int i = 0 ; i < rows; i++){\n",
        "        for(int j = 0; j < cols; j++){\n",
        "            array[i*cols + j] = rand() % 10;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_matrix(int *array, int rows, int cols){\n",
        "    for(int i = 0 ; i < rows; i++){\n",
        "        for(int j = 0; j < cols; j++){\n",
        "            cout << array[i*cols + j] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrix_multiplication_cpu(int *a, int *b, int *c, int common, int c_rows,int c_cols){\n",
        "    for(int i = 0; i < c_rows; i++){\n",
        "        for(int j = 0; j < c_cols; j++){\n",
        "            int sum = 0;\n",
        "            for(int k = 0; k < common; k++){\n",
        "                sum += a[i*common + k] * b[k*c_cols + j];\n",
        "            }\n",
        "            c[i*c_cols + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__ void matrix_multiply(int *a, int *b, int *c, int c_rows, int common, int c_cols)\n",
        "{\n",
        "    int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    int sum=0;\n",
        "\n",
        "    if(col < c_cols && row < c_rows) {\n",
        "      for(int j = 0 ;j < common;j++)\n",
        "      {\n",
        "          sum += a[row*common+j] * b[j*c_cols+col];\n",
        "      }\n",
        "      c[c_cols*row+col]=sum;\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    int A_rows, A_cols, B_rows, B_cols, C_rows, C_cols;\n",
        "    cout << \"Dimensions of matrix 1:\\n\";\n",
        "    cout << \"Rows: \";\n",
        "    cin >> A_rows;\n",
        "    cout << \"Columns: \";\n",
        "    cin >> A_cols;\n",
        "    cout << \"Dimensions of matrix 2:\\n\";\n",
        "    cout << \"Rows: \" << A_cols << endl << \"Columns: \";\n",
        "    cin >> B_cols;\n",
        "    B_rows = A_cols;\n",
        "    C_rows = A_rows;\n",
        "    C_cols = B_cols;\n",
        "\n",
        "    int A_size = A_rows * A_cols;\n",
        "    int B_size = B_rows * B_cols;\n",
        "    int C_size = C_rows * C_cols;\n",
        "\n",
        "    int *A, *B, *C;\n",
        "    int *m1,*m2,*result;\n",
        "\n",
        "    A = new int[A_size];\n",
        "    B = new int[B_size];\n",
        "    C = new int[C_size];\n",
        "\n",
        "    initialize_matrix(A,A_rows,A_cols);\n",
        "    cout << \"Matrix 1\\n\";\n",
        "    // print_matrix(A,A_rows,A_cols);\n",
        "    initialize_matrix(B,B_rows,B_cols);\n",
        "    cout << \"Matrix 2\\n\";\n",
        "    // print_matrix(B,B_rows,B_cols);\n",
        "\n",
        "    cudaMallocManaged(&m1, A_size * sizeof(int));\n",
        "    cudaMallocManaged(&m2, B_size * sizeof(int));\n",
        "    cudaMallocManaged(&result, C_size * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(m1,A,A_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(m2,B,B_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimGrid(A_rows + BLOCK_SIZE  - 1 / BLOCK_SIZE, B_cols + BLOCK_SIZE - 1 / BLOCK_SIZE);\n",
        "    dim3 dimBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
        "\n",
        "    float gpu_elapsed_time;\n",
        "    cudaEvent_t gpu_start,gpu_stop;\n",
        "\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start);\n",
        "    matrix_multiply<<<dimGrid,dimBlock>>>(m1,m2,result,C_rows,A_cols,C_cols);\n",
        "    cudaEventRecord(gpu_stop);\n",
        "    cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "    cudaMemcpy(C,result,C_size*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    cout << \"GPU result:\\n\";\n",
        "    // print_matrix(C,C_rows,C_cols);\n",
        "    cout<<\"GPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start);\n",
        "    matrix_multiplication_cpu(A,B,C,A_cols,C_rows,C_cols);\n",
        "    cudaEventRecord(gpu_stop);\n",
        "    cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "    cout << \"CPU result:\\n\";\n",
        "    // print_matrix(C,C_rows,C_cols);\n",
        "    cout<<\"CPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cudaFree(m1);\n",
        "    cudaFree(m2);\n",
        "    cudaFree(result);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "IN4LzqNzgvFE",
        "outputId": "607bb898-af45-4f69-93b9-b64e587a2d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of matrix 1:\n",
            "Rows: Columns: Dimensions of matrix 2:\n",
            "Rows: 0\n",
            "Columns: Matrix 1\n",
            "Matrix 2\n",
            "GPU result:\n",
            "GPU Elapsed time is: 74.1888 milliseconds\n",
            "CPU result:\n",
            "CPU Elapsed time is: 0.002368 milliseconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}