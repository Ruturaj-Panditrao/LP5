{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "z_75MtwpQ5UW",
        "outputId": "b447c9af-f428-4aac-c197-180a8db1dde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Ruturaj-Panditrao/cuda.git\n",
            "  Cloning https://github.com/Ruturaj-Panditrao/cuda.git to /tmp/pip-req-build-6p4qsz62\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Ruturaj-Panditrao/cuda.git /tmp/pip-req-build-6p4qsz62\n",
            "  Resolved https://github.com/Ruturaj-Panditrao/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=7bcc5d9298463151992f5480ead1b2f8b101f19e57e7eb60752ec383d1ce54bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zstilxb8/wheels/5f/0b/4d/5e62392fd6c7c38253be934211530add4ed3f048c93749d487\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "# Steps to Run Cuda on Google Colab/ Jupyter Notebook\n",
        "# Change runtime to GPU and run this cell\n",
        "\n",
        "!pip install git+https://github.com/Ruturaj-Panditrao/cuda.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Steps to Run Cuda on Linux Command Line (here let us assume file name is abc)\n",
        "# nvcc --version\n",
        "# cat>> abc.cu\n",
        "# Paste the code, then press Ctrl+D\n",
        "# nvcc abc.cu\n",
        "# ./a.out"
      ],
      "metadata": {
        "id": "DMUtuc8XlTyz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that %%cu is required only for Jupyter Notebooks/Google Colabs\n",
        "# If you are running the code as a .cu file, you do not need this declaration.\n",
        "# It basically represents the start of the CUDA code\n",
        "\n",
        "# To understand the code effectively, start from the Main function\n",
        "\n",
        "%%cu\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void add(int* A, int* B, int* C, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // blockIdx.x = Index of Current Block within the Grid\n",
        "    // threadIdx.x = Index of Current Thread within each Block\n",
        "    // blockDim.x = Number of threads per block\n",
        "\n",
        "    // We are basically trying to assign a unique index (thread id or tid) to each thread for processing\n",
        "\n",
        "    if (tid < size) {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "\n",
        "    // If the thread assigned index is within the array bounds, let the thread perform addition\n",
        "}\n",
        "\n",
        "void addCPU(int* A, int*B, int*C, int N)\n",
        "{\n",
        "    for(int i=0; i<N; i++)\n",
        "    {\n",
        "        C[i]=A[i]+B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void initialize(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        vector[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "void print(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        cout << vector[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 10;\n",
        "    // To actually see the difference in CPU and GPU time, set N as 100000, but beware of printing the arrays then :)\n",
        "    // Number of Elements in Each Vector\n",
        "\n",
        "    int* A = new int[N];\n",
        "    int* B = new int[N];\n",
        "    int* C = new int[N];\n",
        "    int* D = new int[N];\n",
        "    // A,B,C,D are allocated memory on the Host (CPU)\n",
        "    // We will use C for the result of addition on GPU\n",
        "    // We will use D for the result of addition on CPU\n",
        "\n",
        "    size_t vectorBytes = N * sizeof(int);\n",
        "    // Finding the memory size of vector\n",
        "\n",
        "    initialize(A, N);\n",
        "    initialize(B, N);\n",
        "    // Initialize A and B vectors with Random Values\n",
        "\n",
        "    cout << \"Vector A: \";\n",
        "    print(A, N);\n",
        "    cout << \"Vector B: \";\n",
        "    print(B, N);\n",
        "\n",
        "    int* X, * Y, * Z;\n",
        "    // X,Y,Z are allocated memory on the Device (GPU)\n",
        "    cudaMalloc(&X, vectorBytes);\n",
        "    cudaMalloc(&Y, vectorBytes);\n",
        "    cudaMalloc(&Z, vectorBytes);\n",
        "\n",
        "    cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    // This is dependent on the GPU architecture\n",
        "\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    float gpu_elapsed_time;\n",
        "    cudaEvent_t gpu_start,gpu_stop;\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start);\n",
        "\n",
        "    add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N);\n",
        "\n",
        "    cudaEventRecord(gpu_stop);\n",
        "    cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "\n",
        "    cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout<<\"GPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cout << \"Addition: \";\n",
        "    print(C, N);\n",
        "\n",
        "    float cpu_elapsed_time;\n",
        "    cudaEvent_t cpu_start,cpu_stop;\n",
        "    cudaEventCreate(&cpu_start);\n",
        "    cudaEventCreate(&cpu_stop);\n",
        "    cudaEventRecord(cpu_start);\n",
        "\n",
        "    addCPU(A,B,D,N);\n",
        "\n",
        "    cudaEventRecord(cpu_stop);\n",
        "    cudaEventSynchronize(cpu_stop);\n",
        "    cudaEventElapsedTime(&cpu_elapsed_time, cpu_start, cpu_stop);\n",
        "    cudaEventDestroy(cpu_start);\n",
        "    cudaEventDestroy(cpu_stop);\n",
        "\n",
        "    cout<<\"CPU Elapsed time is: \"<<cpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cout << \"Addition: \";\n",
        "    print(D, N);\n",
        "\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "    delete[] D;\n",
        "\n",
        "    cudaFree(X);\n",
        "    cudaFree(Y);\n",
        "    cudaFree(Z);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IN4LzqNzgvFE",
        "outputId": "3377313f-fddd-4be1-9f84-9ebeddb973a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: 3 6 7 5 3 5 6 2 9 1 \n",
            "Vector B: 2 7 0 9 3 6 0 6 2 6 \n",
            "GPU Elapsed time is: 102.828 milliseconds\n",
            "Addition: 5 13 7 14 6 11 6 8 11 7 \n",
            "CPU Elapsed time is: 0.002496 milliseconds\n",
            "Addition: 5 13 7 14 6 11 6 8 11 7 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}